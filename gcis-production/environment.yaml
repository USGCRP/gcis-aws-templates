AWSTemplateFormatVersion: '2010-09-09'

Description: 'Application Environment'

Parameters:

  AllowedCIDR:
    Description: 'IPs allowed to connect'
    Type: String
    Default: '0.0.0.0/0'

  AmiId:
    Description: 'The AMI used by the EC2 instance'
    Type: String

  AppServerInstanceType:
    Description: 'The type of EC2 instance used for app servers'
    Type: String

  AsgMinSize:
    Description: 'The minimum number of instances active within an Auto Scaling Group'
    Type: Number
    Default: 1

  AsgMaxSize:
    Description: 'The minimum number of instances active within an Auto Scaling Group'
    Type: Number
    Default: 1

  CertificateARN:
    Description: 'The certificate ARN for this site'
    Type: String
    Default: ''

  ConfigBucketArn:
    Description: 'ARN of S3 bucket that stores configuration files'
    Type: String

  DataBucketArn:
    Description: 'ARN of S3 bucket that stores database dumps'
    Type: String

  DatabaseTemplate:
    Description: 'The key for the correct version of the db template'
    Type: String

  DbClass:
    Description: 'Database instance class'
    Type: String

  DbAdminUserName:
    Description: 'Database admin user name'
    Type: String
    MaxLength: 32

  DbAdminUserPassword:
    Description: 'Database admin user password'
    Type: String
    MinLength: 12
    MaxLength: 32
    NoEcho: true
    ConstraintDescription: 'Database password must be between 12 and 32 chars in length'

  DbStorage:
    Description: 'Amount of storage provisioned'
    Type: Number
    Default: 5
    MinValue: 5
    MaxValue: 6144
    ConstraintDescription: 'Must be between 5 and 6144GB'

  DbBackupRetention:
    Description: 'Number of backups to retain'
    Type: Number
    Default: 7
    MinValue: 0
    MaxValue: 35
    ConstraintDescription: 'Must be a number within the inclusive range of 0 and 35'

  DbMultiAZ:
    Description: 'Create a Multi-AZ RDS database instance'
    Type: String
    Default: false
    AllowedValues:
    - true
    - false

  DomainAlias:
    Description: 'The domain name for this instance'
    Type: String
    Default: ''

  EC2KeyPair:
    Description: 'The SSH key pair in your account to use for all other EC2 instance logins'
    Type: String

  Environment:
    Description: 'Which environment are we building'
    Type: String
    Default: dev
    AllowedValues:
      - prod
      - stage
      - test
      - dev

  ErrorTopic:
    Description: 'SNS topic for errors'
    Type: String

  IAMAccessKey:
    Description: 'Operations Access Key. Should have S3 readwrite'
    Type: String

  IAMSecretKey:
    Description: 'Operations Secret Key.'
    Type: String
    NoEcho: true

  LogRetentionInDays:
    Description: 'Length of time that logs will be retained'
    Type: Number

  NotificationTopic:
    Description: 'SNS topic used for notifications'
    Type: String

  ProjectName:
    Description: 'A short (max 12 chars) project identifier'
    Type: String
    MaxLength: 12
    AllowedPattern: '[a-zA-Z0-9]*'
    ConstraintDescription: 'Project name is limited to 12 alphanumeric characters'

  RootVolSizeGB:
    Description: 'Size of the root volume of an app server'
    Type: Number
    Default: 10

  StackBaseUrl:
    Description: 'S3 bucket containing CF templates'
    Type: String

  UseWebApplicationFirewall:
    Description: 'Use a WAF to restrict access'
    Type: String
    Default: true
    AllowedValues:
    - true
    - false


Conditions:

  UseFirewall: !Equals [ 'true',  !Ref UseWebApplicationFirewall ]

Mappings:

  Constants:
    ValueOf:
      TemplateTimeout: 90
      CloudFrontTtlS3: 15
      CloudFrontTtlSearch: 15

Resources:

  AppServerLogGroup:
    Type: 'AWS::Logs::LogGroup'
    Properties:
      RetentionInDays: !Ref LogRetentionInDays

  AutoScalingGroup:
    Type: 'AWS::AutoScaling::AutoScalingGroup'
    DependsOn: AppDB
    Properties:
      LaunchConfigurationName: !Ref LaunchConfig
      MinSize: !Ref AsgMinSize
      MaxSize: !Ref AsgMaxSize
      DesiredCapacity: !Ref AsgMinSize
      Cooldown: 60
      AutoScalingGroupName: !Sub "${ProjectName}-${Environment}-AutoScalingGroup"
      HealthCheckType: 'EC2'
      HealthCheckGracePeriod: 600
      TargetGroupARNs:
        - !Ref TargetGroup
      VPCZoneIdentifier:
        - 'Fn::ImportValue': !Sub '${ProjectName}-${Environment}-app-subnet-1'
        - 'Fn::ImportValue': !Sub '${ProjectName}-${Environment}-app-subnet-2'
      MetricsCollection:
        - Granularity: '1Minute'
      NotificationConfigurations:
        - TopicARN:
            Ref: NotificationTopic
          NotificationTypes:
          - 'autoscaling:EC2_INSTANCE_LAUNCH'
          - 'autoscaling:EC2_INSTANCE_LAUNCH_ERROR'
          - 'autoscaling:EC2_INSTANCE_TERMINATE'
          - 'autoscaling:EC2_INSTANCE_TERMINATE_ERROR'
        - TopicARN:
            Ref: ErrorTopic
          NotificationTypes:
          - 'autoscaling:EC2_INSTANCE_LAUNCH_ERROR'
          - 'autoscaling:EC2_INSTANCE_TERMINATE_ERROR'
      Tags:
        - PropagateAtLaunch: true
          Value: !Sub '${ProjectName} ${Environment} App Server'
          Key: Name
      TerminationPolicies:
        - OldestInstance
    CreationPolicy:
      ResourceSignal:
        Timeout: PT60M
    UpdatePolicy:
      AutoScalingRollingUpdate:
        PauseTime: PT60M
        WaitOnResourceSignals: true
        MinInstancesInService: 1

  LaunchConfig:
    Type: 'AWS::AutoScaling::LaunchConfiguration'
    Properties:
      KeyName: !Ref EC2KeyPair
      ImageId: !Ref AmiId
      SecurityGroups:
        - !Ref ServerSecurityGroup
      InstanceType: !Ref AppServerInstanceType
      IamInstanceProfile: !Ref ServerProfile
      UserData:
        Fn::Base64: !Sub |
          #!/usr/bin/env bash
          hostnamectl set-hostname "${Environment}-app-$(curl --silent http://169.254.169.254/latest/meta-data/instance-id | tail -c 5)"
          apt-get -y update
          apt-get install -y awscli
          echo -e "\nPermitRootLogin no" >> /etc/ssh/sshd_config
          service sshd restart
          apt-get install -y python-setuptools
          /usr/bin/easy_install --script-dir /opt/aws/bin https://s3.amazonaws.com/cloudformation-examples/aws-cfn-bootstrap-latest.tar.gz
          cp -v /usr/local/lib/python2*/dist-packages/aws_cfn_bootstrap*/init/ubuntu/cfn-hup /etc/init.d
          chmod +x /etc/init.d/cfn-hup
          /opt/aws/bin/cfn-init -v -c server --stack ${AWS::StackName} --resource LaunchConfig --region ${AWS::Region}
          /opt/aws/bin/cfn-signal -e $? --stack ${AWS::StackName} --resource AutoScalingGroup --region ${AWS::Region}
    Metadata:
      AWS::CloudFormation::Init:
        configSets:
          server:
            - "base"
        base:
          files:
            # Setup scripts for GCIS
            '/tmp/setup-gcisops-user':
              mode: '000755'
              content: !Sub |
                #!/usr/bin/env bash
                ###
                # Create the gcisops user
                # Setup their env
                # Setup their AWS config
                ###

                useradd -d /home/gcisops -s '/bin/bash' -m -p $(echo "${DbAdminUserPassword}" | openssl passwd -1 -stdin) gcisops
                echo "export PGHOST=${AppDB.Outputs.HostName}" >>~gcisops/.bashrc
                echo "export PGPORT=${AppDB.Outputs.Port}" >>~gcisops/.bashrc
                echo "export PGDATABASE=gcis" >>~gcisops/.bashrc
                echo "export PGUSER=gcisops" >>~gcisops/.bashrc
                echo "export PGPASSWORD=${DbAdminUserPassword}" >>~gcisops/.bashrc

                echo "[default]" >>~gcisops/.aws/config
                echo "region = us-east-1" >>~gcisops/.aws/config
                echo "output = json" >>~gcisops/.aws/config
                echo "aws_access_key_id = ${IAMAccessKey}" >>~gcisops/.aws/config
                echo "aws_secret_access_key = ${IAMSecretKey}" >>~gcisops/.aws/config
            '/tmp/setup-gcisops-role':
              mode: '000755'
              content: !Sub |
                #!/usr/bin/env bash
                ###
                # Confirm we're lead instance
                # Confirm gcisops user doesn't exist
                # Setup gcisops psql role and permissions
                ###

                # Check if we're the lead instance or exit
                MSG="$(/usr/local/bin/lead_instance.sh)"
                RESULT=$?
                if [[ $RESULT == 1 ]]; then
                  echo "Not lead instance. Skipping Role Create."
                  exit
                fi
                export PGPASSWORD=${DbAdminUserPassword}
                # Check if the gcisops role exists and exit if it does
                psql -U ${DbAdminUserName} -d postgres -p ${AppDB.Outputs.Port} -h ${AppDB.Outputs.HostName} -c "\du" | grep gcisops && echo "gcisops role exists" && exit
                echo "Creating gcisops role"
                # Create gcisops role & set password
                createuser -U ${DbAdminUserName} -p ${AppDB.Outputs.Port} -h ${AppDB.Outputs.HostName} -d gcisops
                psql -U ${DbAdminUserName} -d postgres -p ${AppDB.Outputs.Port} -h ${AppDB.Outputs.HostName} -c "ALTER USER gcisops WITH PASSWORD '${DbAdminUserPassword}'"
                psql -U ${DbAdminUserName} -d postgres -p ${AppDB.Outputs.Port} -h ${AppDB.Outputs.HostName} -c "grant rds_superuser to gcisops;"
            '/tmp/create-gcis-db':
              mode: '000755'
              content: !Sub |
                #!/usr/bin/env bash
                ###
                # Confirm we're lead instance
                # Confirm gcis db doesn't exist
                # Setup gcis db
                ###

                # Check if we're the lead instance or exit
                MSG="$(/usr/local/bin/lead_instance.sh)"
                RESULT=$?
                if [[ $RESULT == 1 ]]; then
                  echo "Not lead instance. Skipping DB create."
                  exit
                fi
                export PGPASSWORD=${DbAdminUserPassword}
                # Check if the gcis database already exists and exit if it does
                MSG="$(/usr/local/bin/database_exists_check.sh)"
                RESULT=$?
                if [[ $RESULT == 0 ]]; then
                  echo "Database Already Exists"
                  exit
                fi
                # create the db
                echo "Creating gcis db"
                createdb -U gcisops -p ${AppDB.Outputs.Port} -h ${AppDB.Outputs.HostName} gcis
            '/tmp/populate-gcis-db':
              mode: '000755'
              content: !Sub |
                #!/usr/bin/env bash
                ###
                # Confirm we're lead instance
                # Confirm gcis db isn't populated
                # Intake latest data from S3 into database
                ###
                # Check if we're the lead instance or exit
                MSG="$(/usr/local/bin/lead_instance.sh)"
                RESULT=$?
                if [[ $RESULT == 1 ]]; then
                  echo "Not lead instance. Skipping DB populate."
                  exit
                fi
                export PGPASSWORD=${DbAdminUserPassword}
                # Check if the gcis database is already populated
                MSG="$(/usr/local/bin/database_populated_check.sh)"
                RESULT=$?
                if [[ $RESULT == 0 ]]; then
                  echo "Database Already Populated"
                  exit
                fi

                echo "Populating gcis db"

                # pull tar from data S3
                REGION=`curl -s http://169.254.169.254/latest/dynamic/instance-identity/document 2>/dev/null | jq -r .region`
                BUCKET=`echo "${DataBucketArn}" | cut -d ":" -f6`

                mkdir /tmp/gcis_data
                aws s3 --region $REGION cp s3://$BUCKET/latest/latest_gcis_database.tar.gz /tmp/gcis_data

                # Populate the data into the database
                cd /tmp/gcis_data
                tar xzvf latest_gcis_database.tar.gz

                # new
                psql gcis -q -f ./gcis_latest.dump
                psql gcis -c "alter database gcis set search_path='gcis_metadata';"

                # old
                #psql -U gcisops -d gcis -p ${AppDB.Outputs.Port} -h ${AppDB.Outputs.HostName} -f ./*_database_schema.dump
                #psql -U gcisops -d gcis -p ${AppDB.Outputs.Port} -h ${AppDB.Outputs.HostName} -f ./*_database_contents_1.dump
                #psql -U gcisops -d gcis -p ${AppDB.Outputs.Port} -h ${AppDB.Outputs.HostName} -f ./*_database_contents_2.dump

                # Set the default path
                #psql -U gcisops -d gcis -p ${AppDB.Outputs.Port} -h ${AppDB.Outputs.HostName} -c "alter database gcis set search_path='gcis_metadata';"
            '/tmp/setup-gcis-prereqs':
              mode: "000755"
              content: !Sub |
                #!/usr/bin/env bash
                ###
                # Install GCIS required system prereqs
                ###
                echo "Installing system prereqs"
                apt-get -y update
                apt-get -y install postgresql-contrib-9.3 libpg-hstore-perl \
                  postgresql-9.3 postgresql-server-dev-9.3 libuuid1 uuid-dev make \
                  openssl libssl-dev libpq-dev graphviz libxml2 raptor2-utils curl \
                  perlbrew git
            '/tmp/setup-gcis-perl':
              mode: "000755"
              content: !Sub |
                #!/usr/bin/env bash
                ###
                # Install GCIS required perl
                ###
                echo "Installing perl 5.20"
                sudo -u gcisops -i bash << EOT
                  perlbrew init
                  echo "source ~/perl5/perlbrew/etc/bashrc" >>~/.bashrc
                  source ~/.bashrc
                  perlbrew install perl-5.20.3 #long running
                  perlbrew install-cpanm
                  perlbrew install-patchperl
                  source ~/.bashrc
                  perlbrew switch perl-5.20.3
                EOT
            '/tmp/setup-gcis-repo':
              mode: "000755"
              content: !Sub |
                #!/usr/bin/env bash
                ###
                # Setup the GCIS repo
                # Grab the correct GCIS config from S3
                # Grab the google secret from S3
                # Setup assets from S3
                ###

                echo "Cloning gcis"
                sudo -u gcisops -i bash << EOU
                  git clone https://github.com/USGCRP/gcis
                  mkdir gcis/log
                EOU

                echo "Grabbing GCIS Config & Google Secret"
                # pull config from S3
                REGION=`curl -s http://169.254.169.254/latest/dynamic/instance-identity/document 2>/dev/null | jq -r .region`
                BUCKET=`echo '${ConfigBucketArn}' | cut -d ':' -f6`

                aws s3 --region $REGION cp s3://$BUCKET/Tuba.conf.${Environment} ~gcisops/gcis/Tuba.conf
                chown gcisops:gcisops ~gcisops/gcis/Tuba.conf

                mkdir -p /var/local/www/assets-back
                chown gcisops:gcisops /var/local/www
                chown gcisops:gcisops /var/local/www/assets-back

                aws s3 --region $REGION cp s3://$BUCKET/gcis_client_secrets.json /usr/local/etc/gcis_client_secrets.json
                chown gcisops:gcisops /usr/local/etc/gcis_client_secrets.json
            '/tmp/setup-gcis-modules':
              mode: "000755"
              content: !Sub |
                #!/usr/bin/env bash
                ###
                # Install GCIS required perl modules
                ###
                echo "Installing GCIS Perl prereqs"
                sudo -u gcisops -i bash << EOF
                  cd gcis
                  cpanm --installdeps --force .
                EOF
            '/tmp/start-gcis':
              mode: "000755"
              content: !Sub |
                #!/usr/bin/env bash
                ###
                # Delay until the database is ready
                # Startup GCIS
                ###
                # Confirm the database is ready with a call trap
                echo "Waiting for GCIS Database to be ready"
                MSG="$(/usr/local/bin/delay_until_database_ready.sh)"
                RESULT=$?
                if [[ $RESULT == 1 ]]; then
                  echo $MSG
                  exit 1
                else
                  echo $MSG
                fi

                echo "Starting GCIS"
                sudo -u gcisops -i bash << EOG
                  /usr/local/bin/gcis_start
                EOG
            # GCIS start & stop scripts
            '/usr/local/bin/gcis_start':
              mode: "000755"
              content: !Sub |
                #!/usr/bin/env bash
                ###
                # Starts up GCIS
                # Assumes you have your env configured for postgres!
                ###
                export MOJO_LOG_LEVEL=debug
                export MOJO_MODE=production

                cd /home/gcisops/gcis
                hypnotoad ./bin/tuba
            '/usr/local/bin/gcis_stop':
              mode: "000755"
              content: !Sub |
                #!/usr/bin/env bash
                ###
                # Stops GCIS
                ###
                cd /home/gcisops/gcis
                hypnotoad -s ./bin/tuba
            # GCIS Content Management Scripts
            '/usr/local/bin/content_release.sh':
              mode: "000755"
              content: !Sub |
                #!/usr/bin/env bash

                ###
                # Send Content to the data-production machines
                #
                # Meant to be run in the data-intake GCIS environment
                # Sends this environments database & assets to AWS S3
                # Gets Dev updated.
                # Gets Test updated.
                # Gets Prod updated.
                ###

                # sync this machine to aws
                echo "Syncing the database and assets from this machine to AWS"
                /usr/local/bin/sync_content_to_aws.sh

                echo "Getting Dev up-to-date"
                ssh gcisops@data-dev.globalchange.gov '/usr/local/bin/sync_content_from_aws.sh'
                DEVSTATUS=`curl -sI https://data-dev.globalchange.gov | grep -o '200 OK'`
                if [ "$DEVSTATUS" = "200 OK" ]; then
                  echo "**** Data-dev updated ****"
                else
                  echo "**** Data-dev replied with non-200 status. Something went wrong! ****"
                  exit
                fi

                echo "Getting Test up-to-date"
                ssh gcisops@data-test.globalchange.gov '/usr/local/bin/sync_content_from_aws.sh'
                TESTSTATUS=`curl -sI https://data-dev.globalchange.gov | grep -o '200 OK'`
                if [ "$TESTSTATUS" = "200 OK" ]; then
                  echo "**** Data-test updated ****"
                else
                  echo "**** Data-test replied with non-200 status. Something went wrong! ****"
                  exit
                fi

                echo "Getting Prod up-to-date"
                ssh gcisops@data.globalchange.gov '/usr/local/bin/sync_content_from_aws.sh'
                PRODSTATUS=`curl -sI https://data.globalchange.gov | grep -o '200 OK'`
                if [ "$PRODSTATUS" = "200 OK" ]; then
                  echo "**** Production updated ****"
                else
                  echo "**** Production replied with non-200 status. Something went really wrong! Contact the GCIS Software Engineer! ****"
                  exit
                fi
            '/usr/local/bin/sync_content_to_aws.sh':
              mode: "000755"
              content: !Sub |
                #!/usr/bin/env bash

                ###
                # Push Content from the data-stage environment to AWS S3
                #
                # Meant to be run on the data-stage GCIS environment
                # Updates the AWS S3 latest to match this environment's database & assets
                # Stores a dated copy of the database in AWS S3
                ###


                REGION=`curl -s http://169.254.169.254/latest/dynamic/instance-identity/document 2>/dev/null | jq -r .region`
                BUCKET=`echo "${DataBucketArn}" | cut -d ":" -f6`

                # aws sync assets
                aws s3 sync --region $REGION /var/local/www/assets-back s3://gcis-databucket-test/assets

                mkdir -p /tmp/gcis_data
                rm -rf /tmp/gcis_data/*

                cd /tmp/gcis_data
                pg_dump gcis > gcis_latest.dump
                tar czvf latest_gcis_database.tar.gz gcis_latest.dump
                TIMESTAMP=`date +%Y%m%d_%H%M%S`
                cp gcis_latest.dump $TIMESTAMP_gcis.dump
                DATE=`date +%Y%m%d`
                tar czvf $TIMESTAMP_gcis_database.tar.gz $TIMESTAMP_gcis.dump

                aws s3 --region $REGION cp s3://$BUCKET/latest/latest_gcis_database.tar.gz /tmp/gcis_data
                aws s3 --region $REGION cp s3://$BUCKET/$DATE/$TIMESTAMP_gcis_database.tar.gz /tmp/gcis_data

                rm -rf /tmp/gcis_data/*
            '/usr/local/bin/sync_content_from_aws.sh':
              mode: "000755"
              content: !Sub |
                #!/usr/bin/env bash

                ###
                # Pull Content from the AWS S3
                #
                # Meant to be run on the data-stable GCIS environments
                # Updates this environment's database & assets to match AWS S3
                ###

                REGION=`curl -s http://169.254.169.254/latest/dynamic/instance-identity/document 2>/dev/null | jq -r .region`
                BUCKET=`echo "${DataBucketArn}" | cut -d ":" -f6`

                # aws sync assets
                aws s3 sync --region $REGION s3://gcis-databucket-test/assets /var/local/www/assets-back

                mkdir -p /tmp/gcis_data
                rm -rf /tmp/gcis_data/*
                aws s3 --region $REGION cp s3://$BUCKET/latest/latest_gcis_database.tar.gz /tmp/gcis_data

                /usr/local/bin/gcis_stop

                # Populate the data into the database
                cd /tmp/gcis_data
                tar xzvf latest_gcis_database.tar.gz
                psql gcis -q -f ./gcis_latest.dump
                psql gcis -c "alter database gcis set search_path='gcis_metadata';"

                /usr/local/bin/gcis_start
            # Utility scripts for checking the ready state
            '/usr/local/bin/delay_until_database_ready.sh':
              mode: "000755"
              content: !Sub |
                #!/usr/bin/env bash
                ###
                # Wait an increasing about of time for the database to report ready.
                #
                # Allows the non-lead instances to delay if the lead instance hasn't finished db setup.
                ###
                DELAY=30
                NOTREADY=1
                MAXATTEMPTS=5
                ATTEMPTS=1
                MSG="$(/usr/local/bin/database_ready.sh)"
                NOTREADY=$?
                echo "Attempt: $ATTEMPTS/$MAXATTEMPTS, delay $DELAY notready $NOTREADY || "
                while (( $NOTREADY )); do
                  if [[ $MAXATTEMPTS == $ATTEMPTS ]]; then
                    echo "Timed out waiting for database to be ready"
                    exit 1
                  fi
                  sleep $DELAY
                  MSG="$(/usr/local/bin/database_ready.sh)"
                  NOTREADY=$?
                  DELAY=$(( DELAY * 2 ))
                  ATTEMPTS=$(( ATTEMPTS + 1 ))
                  echo "Attempt: $ATTEMPTS/$MAXATTEMPTS, delay $DELAY notready $NOTREADY || "
                done
                echo "Found database to be ready after $ATTEMPTS attempts"
                exit 0
            '/usr/local/bin/database_ready.sh':
              mode: "000755"
              content: !Sub |
                #!/usr/bin/env bash
                ###
                # Return whether the database is both existing and populated
                ###
                # Check if the gcis database exists and return 1 if it doesnt
                MSG="$(/usr/local/bin/database_exists_check.sh)"
                RESULT=$?
                if [[ $RESULT == 1 ]]; then
                  echo "Database Not Ready: Doesn't Exist"
                  exit 1
                fi
                # Check if the gcis database is populated and return 1 if it isn't
                MSG2="$(/usr/local/bin/database_populated_check.sh)"
                RESULT2=$?
                if [[ $RESULT2 == 1 ]]; then
                  echo "Database Not Ready: Not Populated"
                  exit 1
                fi
                echo "Database ready"
                exit 0
            '/usr/local/bin/database_exists_check.sh':
              mode: "000755"
              content: !Sub |
                #!/usr/bin/env bash
                ###
                # Return whether the database exists
                ###
                export PGPASSWORD=${DbAdminUserPassword}
                echo "Checking DB exists"
                psql -U gcisops -d postgres \
                  -p ${AppDB.Outputs.Port} \
                  -h ${AppDB.Outputs.HostName} \
                  -c "\l" | grep -q gcis && exit 0
                echo "DB doesn't exist"
                exit 1
            '/usr/local/bin/database_populated_check.sh':
              mode: "000755"
              content: !Sub |
                #!/usr/bin/env bash
                ###
                # Return whether the database is populated
                ###
                export PGPASSWORD=${DbAdminUserPassword}
                echo "Checking DB populated"
                psql -U gcisops -d gcis \
                  -p ${AppDB.Outputs.Port} \
                  -h ${AppDB.Outputs.HostName} \
                  -c "\d" | grep -q "No relations found" || exit 0
                echo "DB not populated"
                exit 1
            # AWS utility to confirm we're the instance in charge
            '/usr/local/bin/lead_instance.sh':
              mode: "000755"
              content: !Sub |
                #!/usr/bin/env bash
                ###
                # Return whether EC2 will be designated the 'lead' instance
                # The lead instance takes charge of doing the environment setup steps
                # related to the database and other once-only setup tasks.
                ###
                INSTANCE_ID=`wget -q -O - http://169.254.169.254/latest/meta-data/instance-id`
                REGION=`curl -s http://169.254.169.254/latest/dynamic/instance-identity/document 2>/dev/null | jq -r .region`

                # Find the Auto Scaling Group name from the Elastic Beanstalk environment
                ASG='${ProjectName}-${Environment}-AutoScalingGroup'

                # Find the first instance in the Auto Scaling Group
                FIRST=`aws autoscaling describe-auto-scaling-groups --auto-scaling-group-names $ASG \
                    --region $REGION --output json | \
                    jq -r '.AutoScalingGroups[].Instances[] | select(.LifecycleState=="InService") | .InstanceId' | sort | head -1`

                echo First Instance: $FIRST
                echo My Instance ID: $INSTANCE_ID
                # If the instance ids are the same exit 0
                [ "$FIRST" = "$INSTANCE_ID" ]
            # Other general setup scripts & config
            '/etc/cron.d/cloudwatch':
              mode: '000644'
              content: |
                */5 * * * * root /opt/aws-scripts-mon/mon-put-instance-data.pl --mem-used --mem-util --swap-used --disk-space-util --disk-path=/ --auto-scaling --from-cron
            '/etc/cron.d/updates':
              mode: '000644'
              content: |
                15 * * * * root apt-get -y update
            '/tmp/cloudwatchlog.conf':
              content: !Sub |
                [general]
                state_file = /var/awslogs/state/agent-state
                use_gzip_http_content_encoding = true
                logging_config_file = /var/awslogs/etc/awslogs.conf
                [/var/log/audit/audit.log]
                file = /var/log/audit/audit.log
                log_stream_name = {instance_id}-/var/log/audit/audit.log
                log_group_name = ${AppServerLogGroup}
                [/var/log/messages]
                datetime_format = %b %d %H:%M:%S
                file = /var/log/messages
                log_stream_name = {instance_id}-/var/log/messages
                log_group_name = ${AppServerLogGroup}
                [/var/log/secure]
                datetime_format = %b %d %H:%M:%S
                file = /var/log/secure
                log_stream_name = {instance_id}-/var/log/secure
                log_group_name = ${AppServerLogGroup}
            '/tmp/config-monitoring':
              mode: '000755'
              content: !Sub |
                #!/usr/bin/env bash
                apt-get -y install zip unzip
                apt-get -y install libwww-perl libdatetime-perl
                cd /opt
                curl http://aws-cloudwatch.s3.amazonaws.com/downloads/CloudWatchMonitoringScripts-1.2.1.zip -O
                unzip CloudWatchMonitoringScripts-1.2.1.zip
                rm CloudWatchMonitoringScripts-1.2.1.zip
                curl https://s3.amazonaws.com/aws-cloudwatch/downloads/latest/awslogs-agent-setup.py -O
                python ./awslogs-agent-setup.py -n --region ${AWS::Region} -c /tmp/cloudwatchlog.conf
                rm -f ./awslogs-agent-setup.py
                service awslogs start
                update-rc.d awslogs enable
            '/etc/systemd/system/awslogs.service':
              content: |
                [Unit]
                Description=The CloudWatch Logs agent
                After=rc-local.service

                [Service]
                Type=simple
                Restart=always
                KillMode=process
                TimeoutSec=infinity
                PIDFile=/var/awslogs/state/awslogs.pid
                ExecStart=/var/awslogs/bin/awslogs-agent-launcher.sh --start --background --pidfile $PIDFILE --user awslogs --chuid awslogs &

                [Install]
                WantedBy=multi-user.target
            '/etc/cfn/cfn-hup.conf':
              content: !Sub |
                [main]
                stack=${AWS::StackId}
                region=${AWS::Region}
            '/etc/cfn/hooks.d/cfn-auto-reloader.conf':
              content: !Sub |
                [cfn-auto-reloader-hook]
                triggers=post.update
                path=Resources.Server.Metadata.AWS::CloudFormation::Init
                action=/opt/aws/bin/cfn-init -v --stack ${AWS::StackId} --region ${AWS::Region} --resource Server
                runas=root
          packages:
            apt:
              jq: []
              postgresql: []
          services:
            sysvinit:
              cfn-hup:
                enabled: true
                ensureRunning: true
                files:
                  - /etc/cfn/cfn-hup.conf
                  - /etc/cfn/hooks.d/cfn-auto-reloader.conf
          commands:
            '01_monitoring':
              command: '/tmp/config-monitoring'
            '02_update':
              command: 'apt-get -y update'
            '03_create_gcisops_user':
              command: '/tmp/setup-gcisops-user'
            '04_create_gcisops_role':
              command: '/tmp/setup-gcisops-role'
            '05_create_gcis_db':
              command: '/tmp/create-gcis-db'
            '06_populate_gcis_db':
              command: '/tmp/populate-gcis-db'
            '07_install_gcis_prereq':
              command: '/tmp/setup-gcis-prereqs'
            '08_install_perl':
              command: '/tmp/setup-gcis-perl'
            '09_setup_repo':
              command: '/tmp/setup-gcis-repo'
            '10_install_perl_modules':
              command: '/tmp/setup-gcis-modules'
            '11_startup_gcis':
              command: '/tmp/start-gcis'

  ServerSecurityGroup:
    Type: 'AWS::EC2::SecurityGroup'
    Properties:
      GroupDescription: 'App Server Access'
      VpcId:
        'Fn::ImportValue': !Sub '${ProjectName}-${Environment}-vpc'
      SecurityGroupIngress:
        - IpProtocol: 'tcp'
          FromPort: 22
          ToPort: 22
          CidrIp:
            'Fn::ImportValue': !Sub '${ProjectName}-management-vpc-cidr'
        - IpProtocol: 'tcp'
          FromPort: 80
          ToPort: 80
          CidrIp: !Ref AllowedCIDR
        - IpProtocol: 'tcp'
          FromPort: 8080
          ToPort: 8080
          CidrIp: !Ref AllowedCIDR
        - IpProtocol: 'tcp'
          FromPort: 443
          ToPort: 443
          CidrIp: !Ref AllowedCIDR

  ServerProfile:
    Type: 'AWS::IAM::InstanceProfile'
    Properties:
      Roles:
        - !Ref ServerRole

  ServerRole:
    Type: 'AWS::IAM::Role'
    Properties:
      ManagedPolicyArns:
        - 'arn:aws:iam::aws:policy/service-role/AmazonEC2RoleforSSM'
      Policies:
        - PolicyName: 'ParamaterStore'
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: 'Allow'
                Action:
                  - 'ssm:*'
                Resource: '*'
        - PolicyName: 'ListConfigBucket'
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: 'Allow'
                Action:
                  - 's3:ListBucket'
                Resource: !Ref ConfigBucketArn
        - PolicyName: 'ConfigBucketRead'
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: 'Allow'
                Action:
                  - 's3:GetObject'
                Resource: !Sub '${ConfigBucketArn}/*'
        - PolicyName: 'ListDataBucket'
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: 'Allow'
                Action:
                  - 's3:ListBucket'
                Resource: !Ref DataBucketArn
        - PolicyName: 'DataBucketRead'
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: 'Allow'
                Action:
                  - 's3:GetObject'
                Resource: !Sub '${DataBucketArn}/*'
        - PolicyName: 'CloudWatchLogs'
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: 'Allow'
                Action:
                  - 'logs:CreateLogGroup'
                  - 'logs:CreateLogStream'
                  - 'logs:PutLogEvents'
                  - 'logs:DescribeLogStreams'
                Resource: !Sub 'arn:aws:logs:${AWS::Region}:${AWS::AccountId}:log-group:${AppServerLogGroup}:*'
        - PolicyName: 'CloudWatchInstanceMonitoring'
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: 'Allow'
                Action:
                  - 'cloudwatch:PutMetricData'
                  - 'cloudwatch:GetMetricStatistics'
                  - 'cloudwatch:ListMetrics'
                  - 'ec2:DescribeTags'
                Resource: '*'
        - PolicyName: 'Notifications'
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: 'Allow'
                Action:
                  - 'SNS:Publish'
                Resource:
                  - !Ref ErrorTopic
                  - !Ref NotificationTopic
        - PolicyName: 'SeeASGs'
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: 'Allow'
                Action:
                  - 'autoscaling:DescribeAutoScalingGroups'
                Resource: '*'
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: 'Allow'
            Principal:
              Service:
                - 'ec2.amazonaws.com'
                - 'ssm.amazonaws.com'
            Action:
              - 'sts:AssumeRole'

  # ~~~ Web Application Firewall ~~~

  WafWebACL:
    Type: 'AWS::WAF::WebACL'
    Condition: UseFirewall
    Properties:
      Name: !Sub '${ProjectName}-${Environment}-WebAppFirewall'
      DefaultAction:
        Type: BLOCK
      MetricName: SecurityAutomationsMaliciousRequesters
      Rules:
        - Action:
            Type: ALLOW
          Priority: 10
          RuleId: !Ref WafWhitelistRule

  WafWhitelistRule:
    Type: 'AWS::WAF::Rule'
    Condition: UseFirewall
    Properties:
      Name: !Sub '${ProjectName}-${Environment}-whitelist-rule'
      MetricName: SecurityAutomationsWhitelistRule
      Predicates:
        - DataId: !Ref WafWhiteListIpSet
          Negated: false
          Type: IPMatch

  WafWhiteListIpSet:
    Type: 'AWS::WAF::IPSet'
    Condition: UseFirewall
    Properties:
      Name: !Sub '${ProjectName}-${Environment}-whitelist-ip-set'
      IPSetDescriptors:
        - Type: IPV4
          Value: '205.175.221.66/32' # NCO Office
        - Type: IPV4
          Value: '205.175.221.67/32' # NCO Office
        - Type: IPV4
          Value: '205.175.221.68/32' # NCO Office
        - Type: IPV4
          Value: '205.175.221.69/32' # NCO Office
        - Type: IPV4
          Value: '205.175.221.70/32' # NCO Office
        - Type: IPV4
          Value: '205.175.221.71/32' # NCO Office
        - Type: IPV4
          Value: '205.175.221.72/32' # NCO Office
        - Type: IPV4
          Value: '205.175.221.73/32' # NCO Office
        - Type: IPV4
          Value: '205.175.221.74/32' # NCO Office
        - Type: IPV4
          Value: '205.175.221.75/32' # NCO Office
        - Type: IPV4
          Value: '205.175.221.76/32' # NCO Office
        - Type: IPV4
          Value: '205.175.221.77/32' # NCO Office
        - Type: IPV4
          Value: '205.175.221.78/32' # NCO Office
        - Type: IPV4
          Value: '198.85.226.0/24' # TSU
        - Type: IPV4
          Value: '199.223.30.254/32' # ICF


  # ~~~ CloudFront Distribution ~~~

  WebsiteCloudfront:
    Type: 'AWS::CloudFront::Distribution'
    Properties:
      DistributionConfig:
        Comment: !Sub '${ProjectName}-${Environment} Cloudfront Distribution'
        WebACLId: !If [ UseFirewall, !Ref WafWebACL, !Ref 'AWS::NoValue' ]
        Origins:
          - DomainName: !GetAtt LoadBalancer.DNSName
            Id: !Sub '${ProjectName}-${Environment}-Server'
            CustomOriginConfig:
              HTTPPort: '80'
              OriginProtocolPolicy: http-only
        Enabled: true
        Aliases:
          - !Ref DomainAlias
        HttpVersion: 'http2'
        DefaultCacheBehavior:
          AllowedMethods:
          - GET
          - HEAD
          Compress: true
          TargetOriginId: !Sub '${ProjectName}-${Environment}-Server'
          MaxTTL: !FindInMap [ Constants, ValueOf, CloudFrontTtlS3 ]
          DefaultTTL: !FindInMap [ Constants, ValueOf, CloudFrontTtlS3 ]
          ForwardedValues:
            QueryString: false
            Cookies:
              Forward: none
          ViewerProtocolPolicy: redirect-to-https
        PriceClass: PriceClass_100 #PriceClass_All
        ViewerCertificate:
          AcmCertificateArn: !Ref CertificateARN
          SslSupportMethod: sni-only
#        Logging:
#          Bucket: !GetAtt LoggingBucket.DomainName


  # ~~~ Load Balancer ~~~

  LoadBalancer:
    Type: 'AWS::ElasticLoadBalancingV2::LoadBalancer'
    Properties:
      Subnets:
        - 'Fn::ImportValue': !Sub '${ProjectName}-${Environment}-dmz-subnet-1'
        - 'Fn::ImportValue': !Sub '${ProjectName}-${Environment}-dmz-subnet-2'
      SecurityGroups:
        - !Ref LbSecurityGroup

  LbSecurityGroup:
    Type: 'AWS::EC2::SecurityGroup'
    Properties:
      GroupDescription: !Sub '${ProjectName}-${Environment} Server Access'
      VpcId:
        'Fn::ImportValue': !Sub '${ProjectName}-${Environment}-vpc'
      SecurityGroupIngress: #TODO: Seemingly no easy way to turn a CSV list into SG rules?
        # Open from anywhere
#        - IpProtocol: tcp
#          FromPort: 80
#          ToPort: 80
#          CidrIp: '0.0.0.0/0'

        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '13.32.0.0/15'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '52.46.0.0/18'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '52.84.0.0/15'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '52.222.128.0/17'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '54.182.0.0/16'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '54.192.0.0/16'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '54.230.0.0/16'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '54.239.128.0/18'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '54.239.192.0/19'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '54.240.128.0/18'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '204.246.164.0/22'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '204.246.168.0/22'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '204.246.174.0/23'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '204.246.176.0/20'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '205.251.192.0/19'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '205.251.249.0/24'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '205.251.250.0/23'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '205.251.252.0/23'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '205.251.254.0/24'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '216.137.32.0/19'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '13.54.63.128/26'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '13.59.250.0/26'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '13.113.203.0/24'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '13.124.199.0/24'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '13.228.69.0/24'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '34.195.252.0/24'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '34.226.14.0/24'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '34.232.163.208/29'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '35.158.136.0/24'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '35.162.63.192/26'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '35.167.191.128/26'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '52.15.127.128/26'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '52.52.191.128/26'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '52.56.127.0/25'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '52.57.254.0/24'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '52.66.194.128/26'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '52.78.247.128/26'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '52.199.127.192/26'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '52.212.248.0/26'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '52.220.191.0/26'
        - IpProtocol: tcp
          FromPort: 80
          ToPort: 80
          CidrIp: '54.233.255.128/26'

  LbListener:
    Type: 'AWS::ElasticLoadBalancingV2::Listener'
    Properties:
      LoadBalancerArn: !Ref LoadBalancer
      Port: 80
      Protocol: HTTP
      DefaultActions:
        - Type: forward
          TargetGroupArn: !Ref TargetGroup

  TargetGroup:
    Type: 'AWS::ElasticLoadBalancingV2::TargetGroup'
    Properties:
      VpcId:
        'Fn::ImportValue': !Sub '${ProjectName}-${Environment}-vpc'
      Port: 8080
      Protocol: HTTP
      Matcher:
        HttpCode: 200-299
      HealthCheckIntervalSeconds: 10
      HealthCheckPath: /
      HealthCheckPort: 8080
      HealthCheckProtocol: HTTP
      HealthCheckTimeoutSeconds: 5
      HealthyThresholdCount: 2
      TargetGroupAttributes:
        - Key: deregistration_delay.timeout_seconds
          Value: 30

  ListenerRule:
    Type: 'AWS::ElasticLoadBalancingV2::ListenerRule'
    Properties:
      ListenerArn: !Ref LbListener
      Priority: 1
      Conditions:
        - Field: path-pattern
          Values:
            - /
      Actions:
        - TargetGroupArn: !Ref TargetGroup
          Type: forward

  # ~~~ Database ~~~

  AppDB:
    Type: 'AWS::CloudFormation::Stack'
    Properties:
      TemplateURL: !Sub '${StackBaseUrl}${DatabaseTemplate}'
      TimeoutInMinutes: !FindInMap [ Constants, ValueOf, TemplateTimeout ]
      Parameters:
        AppId: !Ref ProjectName
        AllocatedStorage: !Ref DbStorage
        BackupRetention: !Ref DbBackupRetention
        DbName: !Sub '${ProjectName}${Environment}'
        DbClass: !Ref DbClass
        DbAdminUsername: !Ref DbAdminUserName
        DbAdminPassword: !Ref DbAdminUserPassword
        Environment: !Ref Environment
        ErrorTopic: !Ref ErrorTopic
        MultiAZDatabase: !Ref DbMultiAZ
        NotificationTopic: !Ref NotificationTopic
        ParamPrefix: !Sub '${ProjectName}/${Environment}'

